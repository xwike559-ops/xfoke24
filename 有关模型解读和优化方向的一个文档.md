## 模型解读

#### HybridFusionNet

![image-20260108170833652](E:\Multi-fusion_cnn-swinv2\image-20260108170833652.png)

- **为什么 patch_size=2？**
  - 多聚焦融合很怕丢细节，patch 太大（如 4/8）会模糊边界
  - 2 是一个“细节保留”和“计算量可控”的折中

虽然只堆了 2 层，但已经能实现“跨窗口信息交换”；如果堆 4/6/8 层，全局性会更强。

#### Lossfunction

**① 梯度最大值保留（核心“清晰度”约束）**

```python
g1 = sobel(img1)
g2 = sobel(img2)
gf = sobel(fused)
grad_max = max(g1, g2)
loss_grad = L1(gf, grad_max)

```

融合图的边缘强度 gf
 应该尽量接近两张输入图中更清晰的那一张（梯度更大的一张）

Sobel 是“粗糙梯度”，对噪声也敏感
 显微图像（类器官）里噪声多，可能把噪声当作“清晰细节”

**② 像素强度一致性（保证亮度/能量）**

```
intensity_target = max(img1, img2)
```

**潜在问题（尤其显微）**：

- 显微成像里“亮”不等于“清晰”
- 细胞/类器官很多结构是暗纹理，max 强度可能把背景抬高、造成偏亮

**③ mask 正则：防止全 0 / 全 1（鼓励“有过渡”）**

##### 损失函数改进：

Lytro 推荐（简单强力版）

1. `loss_detail = L1( LoG(fused), max(LoG(img1), LoG(img2)) )`
2. `loss_ssim = 1 - SSIM(fused, target_soft)`（target_soft 可用清晰度加权）
3. `loss_mask_bin = mean(mask*(1-mask))`
4. `loss_mask_tv = TV(mask)`（可选）

------

✅ 类器官/细胞显微推荐（更稳更贴合）

1. **清晰度加权目标**（Tenengrad/Laplacian energy 生成 w）
2. `loss_detail = Charbonnier( Lap(fused) - Lap(target_soft) )`
3. `loss_lowfreq = L1(blur(fused), blur(0.5*img1+0.5*img2))`（背景一致）
4. `loss_mask_tv = TV(mask)`（强烈推荐）
5. `loss_mask_bin = mean(mask*(1-mask))`（权重调小，防止过早二值化）

## 解惑

- #### **为什么偏移窗口之后需要加入掩码**

可视化：移位窗口注意力的完整流程

1. 输入特征图（4×4 简化示例）

```markdown
原始特征图坐标：
┌────┬────┬────┬────┐
│ 0  │ 1  │ 2  │ 3  │
├────┼────┼────┼────┤
│ 4  │ 5  │ 6  │ 7  │
├────┼────┼────┼────┤
│ 8  │ 9  │ 10 │ 11 │
├────┼────┼────┼────┤
│ 12 │ 13 │ 14 │ 15 │
└────┴────┴────┴────┘
窗口大小: 2×2
```

2. 常规窗口划分 (W-MSA) - 无移位

```markdown
常规窗口 (shift_size=0):
┌───┬───┐┌───┬───┐
│ 0 │ 1 ││ 2 │ 3 │
│ 4 │ 5 ││ 6 │ 7 │
└───┴───┘└───┴───┘
┌───┬───┐┌───┬───┐
│ 8 │ 9 ││ 10│ 11│
│ 12│ 13││ 14│ 15│
└───┴───┘└───┴───┘

窗口1: {0,1,4,5}    窗口2: {2,3,6,7}
窗口3: {8,9,12,13}  窗口4: {10,11,14,15}
```

**注意力计算**：每个窗口内部计算自注意力，窗口间**不通信**

3. 移位窗口划分 (SW-MSA) - 关键步骤

```markdown
移位 (shift_size=1, 向右下移动1个像素):
torch.roll(x, shifts=(-1,-1), dims=(1,2))

移位后特征图：
┌────┬────┬────┬────┐
│ 5  │ 6  │ 7  │ 4  │
├────┼────┼────┼────┤
│ 9  │ 10 │ 11 │ 8  │
├────┼────┼────┼────┤
│ 13 │ 14 │ 15 │ 12 │
├────┼────┼────┼────┤
│ 1  │ 2  │ 3  │ 0  │
└────┴────┴────┴────┘
```

4. 在移位特征图上划分窗口 (2×2)

```markdown
移位后的窗口划分：
┌───┬───┐┌───┬───┐
│ 5 │ 6 ││ 7 │ 4 │
│ 9 │ 10││ 11│ 8 │
└───┴───┘└───┴───┘
┌───┬───┐┌───┬───┐
│ 13│ 14││ 15│ 12│
│ 1 │ 2 ││ 3 │ 0 │
└───┴───┘└───┴───┘

窗口1: {5,6,9,10}   窗口2: {7,4,11,8}
窗口3: {13,14,1,2}  窗口4: {15,12,3,0}
```

5. 问题来了：不自然的窗口组合

**窗口3包含不相邻的像素**：

- 位置13, 14（原特征图的第3行）
- 位置1, 2（原特征图的第0行）

在**原始空间**中，位置1和13不相邻，不应该互相计算注意力！这就是需要**掩码**的原因。

掩码**不是**阻止窗口间信息交换，而是**精确控制**交换的方式。它确保**只有相邻的原始窗口之间能交换信息**，而不是让所有像素随意混合。

- #### `patch_size` 的参数意义是什么？

  - **每个 token 对应原特征图上多大的一块区域（patch）**
     同时也是 **下采样倍率**（stride=patch_size）

- **将注意力头数量（num_heads）增加会有什么影响？**
  - **影响 1：表达能力变化（更“细分视角”）**
    - 多头注意力可以理解为：**同时用多种“相似度度量方式”去看同一个窗口**
    - heads 越多，模型更容易学到不同类型关系（边缘、纹理、结构、对比度等）
  - **每个 head 的维度会变小（重要）**
    - ead_dim 太小可能导致每个头的信息容量不足，反而效果不一定更好。
- **为什么 Transformer 部分对初始化很敏感？**
  - Transformer 里面有三类“敏感算子”，一旦初始权重尺度不合适，就容易训练不稳（梯度爆炸/消失、softmax 饱和等）。

## 想法

#### CNN模块

空洞卷积

#### SWIN模块

根据信息量**自适应分解窗大小**，注意窗口大小一定要能将图像大小整除，8的倍数

对于DSE**现象的消除策略**













尺寸适配（关键）：
Swin Transformer 对图像尺寸有严格要求（必须是 window_size 的倍数）。你的原始图像是 520x520。
如果 PatchSize=2, WindowSize=8，特征图大小为 260，260/8 = 32.5（不整除，会报错）。
解决方案：我在 MultiFocusDataset 中将 resize 默认设为 512x512（CV领域标准尺寸，且被8整除）。这是最稳健的做法，避免复杂的动态Padding导致的边缘伪影。
依赖项：
代码依赖 timm 库（PyTorch Image Models），这是Swin Transformer的标准实现库。如果未安装，请先运行 pip install timm。
可视化增强：
不仅显示融合图，现在还会显示决策图（Decision Mask）。这在写论文时是证明模型“真的学到了聚焦区域”的最强证据。
损失函数升级：
移除了可能导致模糊的 MSE，换成了梯度引导损失（Gradient Loss）和Mask二值化约束。